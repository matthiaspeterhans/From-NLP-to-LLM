{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3747636d",
   "metadata": {},
   "source": [
    "# Solutions – Week 2\n",
    "**Course:** NLP and Text Mining  \n",
    "**Group C:** Choekyel Nyungmartasang, Vincent Gaspoz, Marc Anton Nanzer, Matthias Johannes Peterhans  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8129e3ee",
   "metadata": {},
   "source": [
    "## Summary\n",
    "In this week, we explored text processing (regex, stemming, lemmatization) and text mining (cosine similarity, Naive Bayes, and neural models).  \n",
    "We learned how to preprocess medical text, create rule-based and learned NER models, and understand when sequence modeling is necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665f6d72",
   "metadata": {},
   "source": [
    "___\n",
    "# Q&A "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b38295",
   "metadata": {},
   "source": [
    "___\n",
    "## Part 1: Text Processing\n",
    "\n",
    "### 1) Read the subsections 2.7.1-2.7.3 from https://web.stanford.edu/~jurafsky/slp3/2.pdf. It describes regular expressions. Explain how they can be used to find ICD-10 codes in a medical texts and what disadvantages it implies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9478715",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "icd_general = re.compile(\n",
    "    r\"(?i)(?<![A-Z0-9])[A-Z]\\s?\\d{2}(?:[.\\---]?\\s?[0-9]{1,4})?(?![A-Z0-9])\"\n",
    ")\n",
    "text =\"\"\"\n",
    "Dx: A41.9 suspected. Prior I10. Label shows A 41 9; PDF split A41\n",
    "- 9, Also note U07.1 and C50-C54 range.\n",
    "    \"\"\"\n",
    "\n",
    "codes = [m.group(0).replace(\" \", \"\") for m in icd_general.finditer(text)]\n",
    "print (codes) # ['A41.9\", \"I10', \"A419', \"A41-9\", \"U07.1'|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1256246",
   "metadata": {},
   "source": [
    "ICD-10 codes follow a pattern: one letter, two digits, and sometimes a decimal point with more letters/numbers (e.g. E11.9 (Type 2 diabetes)).\n",
    "\n",
    "We can use regex to find these patterns in medical texts. A regex pattern for ICD-10 codes could be something like:\n",
    "\n",
    "```\n",
    "(?i)(?<![A-Z0-9])[A-Z]\\s?\\d{2}(?:[.\\-]?\\s?[0-9]{1,4})?(?![A-Z0-9])\n",
    "```\n",
    "This regex breaks down as follows:\n",
    "- `(?i)`: Case insensitive matching.\n",
    "- `(?<![A-Z0-9])`: Negative lookbehind to ensure the code\n",
    "    is not preceded by another letter or digit.\n",
    "- `[A-Z]`: Matches a single uppercase letter.\n",
    "- `\\s?`: Matches an optional space.\n",
    "- `\\d{2}`: Matches exactly two digits.\n",
    "- `(?:[.\\-]?\\s?[0-9]{1,4})?\n",
    ": Non-capturing group that matches an optional decimal point or hyphen, followed by an optional space and 1 to 4 digits.\n",
    "- `(?![A-Z0-9])`: Negative lookahead to ensure the code is\n",
    "    not followed by another letter or digit.\n",
    "\n",
    "\n",
    "So, if we run this regex on a hospital note like: “Patient diagnosed with E11.9 and later admitted for U07.1”. It will find E11.9 and U07.1 as ICD-10 codes.\n",
    "\n",
    "Disadvantages could be that regex might pick up things that look like ICD-10 codes but are not. Like for example a product code. Regex is also context independent, meaning it can not handle negation or temporal meaning. For example, “exclude E11.9”, it will still take the ICD-10 code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf72ddd",
   "metadata": {},
   "source": [
    "### 2) Solve the three exercises in the Jupyter notebook Spacy-excercises.ipynb in the materials of week 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2453938",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup\n",
    "!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f606be24",
   "metadata": {},
   "source": [
    "### Excercise 2.1: Named Entity Recognition (NER) with spaCy\n",
    "- Which entities did spaCy detect?\n",
    "- Which important terms were missed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d416e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the small English pipeline\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "# Example medical text\n",
    "text = \"The patient was prescribed 5 mg of Prednisone in Zurich.\"\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "# Print detected entities\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26efbd25",
   "metadata": {},
   "source": [
    "### Answer 2.1\n",
    "spaCy detected:\n",
    "- \"5 mg\" as QUANTITY\n",
    "- \"Prednisone\" as Geopolitical entity (GPE)\n",
    "- \"Zurich\" as Geopolitical entity (GPE)\n",
    "\n",
    "Missed entities:\n",
    "- \"Prednisone\" should be a drug/medication, not a location (GPE).\n",
    "- The text contains no explicit disease mention, so nothing else was tagged."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9692ec",
   "metadata": {},
   "source": [
    "### Exercise 2.2: Custom Rule-Based Matcher\n",
    "- Describe the what the following code is doing.\n",
    "- What are problems with coding like that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae878d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add EntityRuler properly (v3 syntax)\n",
    "ruler = nlp.add_pipe(\"entity_ruler\", before=\"ner\")\n",
    "\n",
    "# Define patterns\n",
    "dosage_pattern = [{\"LIKE_NUM\": True}, {\"LOWER\": {\"IN\": [\"mg\", \"ml\", \"g\"]}}]\n",
    "med_suffix_pattern = [{\"TEXT\": {\"REGEX\": \"(?i).*(ine|ol|pril|sartan|mab)$\"}}]\n",
    "med_list_pattern = [{\"LOWER\": {\"IN\": [\"prednisone\", \"ibuprofen\", \"paracetamol\", \"metformin\"]}}]\n",
    "route_pattern = [{\"LOWER\": {\"IN\": [\"po\", \"iv\", \"im\", \"sc\"]}}]\n",
    "freq_pattern = [{\"LOWER\": {\"IN\": [\"once\", \"twice\"]}}, {\"LOWER\": {\"IN\": [\"daily\", \"weekly\"]}}]\n",
    "\n",
    "# Add patterns\n",
    "ruler.add_patterns([\n",
    "    {\"label\": \"DOSAGE\", \"pattern\": dosage_pattern},\n",
    "    {\"label\": \"MEDICATION\", \"pattern\": med_suffix_pattern},\n",
    "    {\"label\": \"MEDICATION\", \"pattern\": med_list_pattern},\n",
    "    {\"label\": \"ROUTE\", \"pattern\": route_pattern},\n",
    "    {\"label\": \"FREQUENCY\", \"pattern\": freq_pattern},\n",
    "])\n",
    "\n",
    "# Example text\n",
    "text = \"The patient was prescribed 5 mg of Prednisone in Zurich. Later, they took 10 ml ibuprofen PO twice daily.\"\n",
    "doc = nlp(text)\n",
    "\n",
    "print(\"Entities:\")\n",
    "for ent in doc.ents:\n",
    "    print(f\"- {ent.text!r:>12}  ->  {ent.label_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a659c89f",
   "metadata": {},
   "source": [
    "### Answer 2.2\n",
    "\n",
    "The code loads spaCy English model (before it was the small model but since I already downloaded the medium model I changed for that.)\n",
    "\n",
    "It adds an EntitiyRuler before the built in NER model. This allows custom rules to tag entities first.\n",
    "\n",
    "Then patterns for speficif medical concepts are defined. Like DOSAGE -> numbers followed by units (mg, ml, g) or MEDICATION -> either words ending with typical drug suffixes like -ine, -ol, -pril or a custom list of known drugs like Prednisone, Ibuprofen.\n",
    "\n",
    "These are then added to the ruler so they become recognized entities.\n",
    "\n",
    "The text is than ran on the pipeline and detected entities are printed. This fixes the earlier problem of medication being tagged as location.\n",
    "\n",
    "Problems with coding like this is that the patterns are assumed to be complete. Meaning, new drug names, unusual dosages or different frequency phrases will be missed if not included in the patterns. It is also not scalable. To manually find out and write all the patterns is expensive. There is also a risk of false positives when using patterns which rely on suffix. For example a word ending on -ol like \"alcohol\" may be wrongly tagged as a medication.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5affc73",
   "metadata": {},
   "source": [
    "### Exercise 3.3: Train a tiny custom NER model in spaCy\n",
    "- Run the code and inspect output.\n",
    "- Try adding 5–6 new entity types (e.g., SYMPTOM, LAB_TEST, DEVICE, ROUTE, DURATION, FREQUENCY) with just 1–2 examples each to see how training reacts.\n",
    "- Evaluate qualitatively: What does the model get right/wrong?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59f772f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA = [\n",
    "    (\"The patient received 5 mg Prednisone.\", \n",
    "     {\"entities\": [(20, 24, \"DOSAGE\"), (25, 35, \"DRUG\")]}),\n",
    "    (\"Pain in the left knee improved after ibuprofen.\", \n",
    "     {\"entities\": [(12, 21, \"BODY_PART\"), (33, 42, \"DRUG\")]}),\n",
    "    (\"He was given 2 ml epinephrine IM.\", \n",
    "     {\"entities\": [(12, 16, \"DOSAGE\"), (17, 27, \"DRUG\")]}),\n",
    "    (\"CT showed a 2 cm lesion in the liver.\", \n",
    "     {\"entities\": [(12, 16, \"MEASUREMENT\"), (31, 36, \"BODY_PART\")]}),\n",
    "    (\"Administer 10 mg morphine intravenously.\", \n",
    "     {\"entities\": [(11, 16, \"DOSAGE\"), (17, 25, \"DRUG\")]}),\n",
    "    (\"MRI confirmed swelling in the brain.\", \n",
    "     {\"entities\": [(28, 33, \"BODY_PART\")]}),\n",
    "    (\"Patient reported headache, treated with aspirin.\", \n",
    "     {\"entities\": [(17, 25, \"BODY_PART\"), (40, 47, \"DRUG\")]}),\n",
    "    (\"She received 250 mg amoxicillin for 5 days.\", \n",
    "     {\"entities\": [(13, 19, \"DOSAGE\"), (20, 31, \"DRUG\")]}),\n",
    "    (\"X-ray revealed fracture in the right arm.\", \n",
    "     {\"entities\": [(35, 43, \"BODY_PART\")]}),\n",
    "    (\"The doctor prescribed 20 mg omeprazole daily.\", \n",
    "     {\"entities\": [(24, 29, \"DOSAGE\"), (30, 40, \"DRUG\")]}),\n",
    "    (\"Ultrasound detected a 5 cm cyst in the kidney.\", \n",
    "     {\"entities\": [(24, 28, \"MEASUREMENT\"), (40, 46, \"BODY_PART\")]}),\n",
    "    (\"Patient complained of chest pain, given nitroglycerin.\", \n",
    "     {\"entities\": [(22, 27, \"BODY_PART\"), (35, 48, \"DRUG\")]}),\n",
    "    (\"Treatment started with 8 mg dexamethasone.\", \n",
    "     {\"entities\": [(22, 26, \"DOSAGE\"), (27, 40, \"DRUG\")]}),\n",
    "    (\"Examination revealed tumor in the stomach.\", \n",
    "     {\"entities\": [(32, 39, \"BODY_PART\")]}),\n",
    "    (\"She was prescribed 50 mg sertraline at night.\", \n",
    "     {\"entities\": [(19, 24, \"DOSAGE\"), (25, 35, \"DRUG\")]}),\n",
    "]\n",
    "\n",
    "TRAIN_DATA += [\n",
    "    (\"The patient complained of stomachache.\", \n",
    "     {\"entities\": [(25, 33, \"SYMPTOM\")]}),\n",
    "\n",
    "    (\"Blood test showed high glucose.\", \n",
    "     {\"entities\": [(0, 10, \"LAB_TEST\")]}),\n",
    "\n",
    "    (\"The surgeon implanted a pacemaker.\", \n",
    "     {\"entities\": [(25, 34, \"DEVICE\")]}),\n",
    "\n",
    "    (\"The drug was given IV.\", \n",
    "     {\"entities\": [(18, 20, \"ROUTE\")]}),\n",
    "\n",
    "    (\"She took antibiotics for 7 days.\", \n",
    "     {\"entities\": [(26, 32, \"DURATION\")]}),\n",
    "\n",
    "    (\"Medication was prescribed twice daily.\", \n",
    "     {\"entities\": [(26, 37, \"FREQUENCY\")]}),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16fcb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.training.example import Example\n",
    "import random\n",
    "\n",
    "# from train_data import TRAIN_DATA\n",
    "\n",
    "# Blank English pipeline\n",
    "nlp = spacy.blank(\"en\")\n",
    "ner = nlp.add_pipe(\"ner\")\n",
    "\n",
    "# Add labels\n",
    "for _, annotations in TRAIN_DATA:\n",
    "    for ent in annotations.get(\"entities\"):\n",
    "        ner.add_label(ent[2])\n",
    "\n",
    "# Convert to spaCy examples\n",
    "examples = []\n",
    "for text, ann in TRAIN_DATA:\n",
    "    doc = nlp.make_doc(text)\n",
    "    examples.append(Example.from_dict(doc, ann))\n",
    "\n",
    "# Training loop\n",
    "optimizer = nlp.initialize()\n",
    "for epoch in range(20):\n",
    "    random.shuffle(examples)\n",
    "    losses = {}\n",
    "    for ex in examples:\n",
    "        nlp.update([ex], sgd=optimizer, losses=losses)\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f\"Epoch {epoch+1}, Losses: {losses}\")\n",
    "\n",
    "# Test on new text\n",
    "#test_text = \"The nurse gave 10 mg morphine for arm pain.\"\n",
    "test_text = \"The nurse gave 10 mg morphine for arm pain. The patient had stomachache and rested for 5 days. Then the patient worked out once a week. Later he got chest pain\"\n",
    "doc = nlp(test_text)\n",
    "print([(ent.text, ent.label_) for ent in doc.ents])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db2a828",
   "metadata": {},
   "source": [
    "### Answer 3.3\n",
    "\n",
    "With even a few examples the model can generalize to unseen sentences. So it learns simple, repetitive patterns well. \n",
    "\n",
    "The limitations are that the model only memorizes patterns and is not robust for general rules. There is also the problem of overlapping labels. Like \"chest pain\" could be both SYMPTOM and a BODY_PART. Also using only 1-2 training examples added no value. At least 5 examples per new label may be needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed0babb",
   "metadata": {},
   "source": [
    "### 3) Discuss briefly why and when to use a stemmer, when one can have lemmatizer?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ec68a1",
   "metadata": {},
   "source": [
    "Use a stemmer if you want a fast and rough normalization of words. Stemmer is good for tasks like search engines or indexing where exact grammar is not that important. Example: studies -> studi, running -> run.\n",
    "\n",
    "Use a lemmatizer if you need the true dictionary base form of words. Lemmatizer is better for linguistic analysis, information extraction and ML models that rely on correct word forms.\n",
    "\n",
    "Example: better -> good, running (verb) -> run, running (noun) -> running."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106af04f",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Text Mining \n",
    "\n",
    "### 1) Solve the exercise on slide 10 of week 3. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a584db",
   "metadata": {},
   "source": [
    "- The cosine similarity of 0.3 means the reports share only a small overlap in symptoms.\n",
    "\n",
    "- Cosine similarity and normalized Euclidean distance are not the same, but they are mathematically related. High cosine similarity means a small Euclidean distance!\n",
    "\n",
    "- Yes, results improve with SNOMED CT because it normalizes terms and captures relationships between symptoms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bcb4d0",
   "metadata": {},
   "source": [
    "### 2) Make the code in Sentiment-NB.jpynb in the materials of week 3 run on your machine. The three data text files are in the folder data of week 3. Why is padding the text not useful here?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e813c5f9",
   "metadata": {},
   "source": [
    "Because the classifier Naïve Bayes with TF-IDF does not process sequences of fixed length like a neural network does. Instead, it represents each document as a bag of words. Which is an unordered vector of word frequencies or importance weights. Also the position or order of words is not used, so padding to make all texts equal length does not affect anything. Padding only matters in models that handle sequential input (e.g., RNNs, LSTMs, Transformers) where word order and length influence the output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6162c7c4",
   "metadata": {},
   "source": [
    "### 3) Tweak the neural network in section \"Neural Network\" of Sentiment-NB.jpynb such that the accuracy is above 80%. Is GlobalAveragePooling1D useful here?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a261c313",
   "metadata": {},
   "source": [
    "No, not for this task. It just averages embeddings and ignores the order of words. So phrases like “not bad” and “bad not” look similar. LSTM captures sequence order and is better for sentiment classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b418f2be",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
